from typing import List, Dict, Any, Optional
from app.services.llm_service import LLMService
import logging
import json
import asyncio
from concurrent.futures import ThreadPoolExecutor

logger = logging.getLogger(__name__)

class RelevanceFilteringService:
    """ê´€ë ¨ì„± ê¸°ë°˜ ì½˜í…ì¸  í•„í„°ë§ ì„œë¹„ìŠ¤
    
    ìˆ˜ì§‘ëœ ê²Œì‹œë¬¼ê³¼ ëŒ“ê¸€ ì¤‘ì—ì„œ í‚¤ì›Œë“œì™€ ì‹¤ì œë¡œ ê´€ë ¨ì„±ì´ ë†’ì€ ë‚´ìš©ë§Œ ì„ ë³„í•˜ì—¬
    ë³´ê³ ì„œ í’ˆì§ˆì„ í–¥ìƒì‹œí‚¤ëŠ” LLM ê¸°ë°˜ í•„í„°ë§ ì‹œìŠ¤í…œ
    """
    
    def __init__(self, thread_pool: Optional[ThreadPoolExecutor] = None, api_semaphore: Optional[asyncio.Semaphore] = None):
        self.llm_service = LLMService(api_semaphore=api_semaphore)
        self.thread_pool = thread_pool
        self.api_semaphore = api_semaphore
        
        # ê´€ë ¨ì„± ì ìˆ˜ ì„ê³„ê°’
        self.RELEVANCE_THRESHOLD = 6.0  # 10ì  ë§Œì  ì¤‘ 6ì  ì´ìƒë§Œ í†µê³¼
        self.MIN_HIGH_QUALITY_POSTS = 10  # ìµœì†Œ 10ê°œì˜ ê³ í’ˆì§ˆ ê²Œì‹œë¬¼ ë³´ì¥
        self.MAX_CONTENT_ITEMS = 50  # ìµœëŒ€ 50ê°œ ì•„ì´í…œ ì²˜ë¦¬ (ì„±ëŠ¥ ê³ ë ¤)
    
    async def filter_relevant_content(
        self, 
        content_items: List[Dict[str, Any]], 
        query: str, 
        expanded_keywords: List[str] = None
    ) -> List[Dict[str, Any]]:
        """ê´€ë ¨ì„± ê¸°ë°˜ ì½˜í…ì¸  í•„í„°ë§
        
        Args:
            content_items: ê²Œì‹œë¬¼ê³¼ ëŒ“ê¸€ì´ í¬í•¨ëœ ì½˜í…ì¸  ëª©ë¡
            query: ì›ë³¸ ê²€ìƒ‰ í‚¤ì›Œë“œ
            expanded_keywords: í™•ì¥ëœ í‚¤ì›Œë“œ ëª©ë¡
        
        Returns:
            ê´€ë ¨ì„±ì´ ë†’ì€ ì½˜í…ì¸ ë§Œ ì„ ë³„ëœ ëª©ë¡
        """
        if not content_items:
            logger.warning("ğŸ“­ í•„í„°ë§í•  ì½˜í…ì¸ ê°€ ì—†ìŠµë‹ˆë‹¤")
            return []
        
        logger.info(f"ğŸ” ê´€ë ¨ì„± í•„í„°ë§ ì‹œì‘ - ëŒ€ìƒ: {len(content_items)}ê°œ ì½˜í…ì¸ ")
        logger.info(f"   í‚¤ì›Œë“œ: '{query}'")
        if expanded_keywords:
            logger.info(f"   í™•ì¥ í‚¤ì›Œë“œ: {len(expanded_keywords)}ê°œ")
        
        # ì„±ëŠ¥ì„ ìœ„í•´ ì½˜í…ì¸  ìˆ˜ ì œí•œ
        if len(content_items) > self.MAX_CONTENT_ITEMS:
            logger.info(f"âš¡ ì„±ëŠ¥ ìµœì í™”ë¥¼ ìœ„í•´ ìƒìœ„ {self.MAX_CONTENT_ITEMS}ê°œ ì½˜í…ì¸ ë§Œ í•„í„°ë§")
            # ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ìƒìœ„ ì½˜í…ì¸  ì„ ë³„
            content_items = sorted(content_items, key=lambda x: x.get('score', 0), reverse=True)[:self.MAX_CONTENT_ITEMS]
        
        # ì½˜í…ì¸ ë¥¼ ë°°ì¹˜ë¡œ ë‚˜ëˆ„ì–´ ì²˜ë¦¬ (LLM API íš¨ìœ¨ì„±ì„ ìœ„í•´)
        batch_size = 10  # í•œ ë²ˆì— 10ê°œì”© ì²˜ë¦¬
        batches = [content_items[i:i + batch_size] for i in range(0, len(content_items), batch_size)]
        
        all_filtered_content = []
        
        for batch_idx, batch in enumerate(batches):
            try:
                logger.info(f"ğŸ” ë°°ì¹˜ {batch_idx + 1}/{len(batches)} ì²˜ë¦¬ ì¤‘ ({len(batch)}ê°œ ì½˜í…ì¸ )")
                
                # ë°°ì¹˜ë³„ ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚°
                scored_content = await self._score_content_relevance(batch, query, expanded_keywords)
                
                # ì„ê³„ê°’ ì´ìƒì˜ ì½˜í…ì¸ ë§Œ ì„ ë³„
                filtered_batch = [
                    item for item in scored_content 
                    if item.get('relevance_score', 0) >= self.RELEVANCE_THRESHOLD
                ]
                
                all_filtered_content.extend(filtered_batch)
                logger.info(f"âœ… ë°°ì¹˜ {batch_idx + 1} ì™„ë£Œ: {len(filtered_batch)}/{len(batch)}ê°œ í†µê³¼")
                
            except Exception as e:
                logger.error(f"âŒ ë°°ì¹˜ {batch_idx + 1} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì›ë³¸ ì½˜í…ì¸ ë¥¼ ê·¸ëŒ€ë¡œ í¬í•¨ (ì•ˆì •ì„± ìš°ì„ )
                all_filtered_content.extend(batch)
                continue
        
        # ê´€ë ¨ì„± ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
        all_filtered_content.sort(key=lambda x: x.get('relevance_score', 0), reverse=True)
        
        # ìµœì†Œ ê³ í’ˆì§ˆ ê²Œì‹œë¬¼ ìˆ˜ ë³´ì¥
        final_content = self._ensure_minimum_quality_content(all_filtered_content, content_items)
        
        logger.info(f"ğŸ¯ ê´€ë ¨ì„± í•„í„°ë§ ì™„ë£Œ")
        logger.info(f"   ì›ë³¸: {len(content_items)}ê°œ â†’ í•„í„°ë§ í›„: {len(final_content)}ê°œ")
        logger.info(f"   í‰ê·  ê´€ë ¨ì„± ì ìˆ˜: {self._calculate_average_score(final_content):.1f}/10")
        
        return final_content
    
    async def _score_content_relevance(
        self, 
        content_batch: List[Dict[str, Any]], 
        query: str, 
        expanded_keywords: List[str] = None
    ) -> List[Dict[str, Any]]:
        """ì½˜í…ì¸  ë°°ì¹˜ì˜ ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚°"""
        
        # í‚¤ì›Œë“œ ëª©ë¡ ì¤€ë¹„
        all_keywords = [query]
        if expanded_keywords:
            all_keywords.extend(expanded_keywords[:10])  # ìƒìœ„ 10ê°œ í‚¤ì›Œë“œë§Œ ì‚¬ìš©
        
        # ì½˜í…ì¸  ì •ë³´ë¥¼ LLMìš© í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
        content_descriptions = []
        for idx, item in enumerate(content_batch):
            item_type = item.get('type', 'unknown')
            title = item.get('title', 'ì œëª© ì—†ìŒ') if item_type == 'post' else 'ëŒ“ê¸€'
            content = item.get('content', item.get('selftext', 'ë‚´ìš© ì—†ìŒ'))[:300]  # 300ì ì œí•œ
            score = item.get('score', 0)
            
            description = f"""[{idx + 1}] {item_type.upper()}: {title}
ë‚´ìš©: {content}
ì ìˆ˜: {score}
---"""
            content_descriptions.append(description)
        
        prompt = f"""ë‹¤ìŒì€ "{query}" í‚¤ì›Œë“œë¡œ ìˆ˜ì§‘ëœ ì½˜í…ì¸ ë“¤ì…ë‹ˆë‹¤.

ê´€ë ¨ í‚¤ì›Œë“œ: {', '.join(all_keywords)}

ìˆ˜ì§‘ëœ ì½˜í…ì¸ :
{chr(10).join(content_descriptions)}

ê° ì½˜í…ì¸ ì˜ ê´€ë ¨ì„±ì„ 0-10ì ìœ¼ë¡œ í‰ê°€í•´ì£¼ì„¸ìš”:

í‰ê°€ ê¸°ì¤€:
- 9-10ì : í‚¤ì›Œë“œì™€ ì§ì ‘ì ìœ¼ë¡œ ë§¤ìš° ê´€ë ¨ì„±ì´ ë†’ìŒ (í•µì‹¬ ë‚´ìš©)
- 7-8ì : í‚¤ì›Œë“œì™€ ê´€ë ¨ì„±ì´ ë†’ìŒ (ì¤‘ìš”í•œ ë‚´ìš©)  
- 5-6ì : í‚¤ì›Œë“œì™€ ì–´ëŠ ì •ë„ ê´€ë ¨ì„± ìˆìŒ (ì°¸ê³  ë‚´ìš©)
- 3-4ì : í‚¤ì›Œë“œì™€ ê°„ì ‘ì ìœ¼ë¡œë§Œ ê´€ë ¨ë¨ (ë¶€ì°¨ì  ë‚´ìš©)
- 0-2ì : í‚¤ì›Œë“œì™€ ê´€ë ¨ì„±ì´ ê±°ì˜ ì—†ìŒ (ë¬´ê´€í•œ ë‚´ìš©)

íŠ¹ë³„ ê³ ë ¤ì‚¬í•­:
- êµ¬ì²´ì ì¸ ì‚¬ë¡€, ê²½í—˜ë‹´, ë°ì´í„°ê°€ í¬í•¨ëœ ì½˜í…ì¸ ëŠ” ê°€ì 
- ì¶”ì¸¡ì„±, ë£¨ë¨¸ì„± ë‚´ìš©ì€ ê°ì 
- ê°ì •ì  ë°˜ì‘ë§Œ ìˆê³  ì‹¤ì§ˆì  ì •ë³´ê°€ ì—†ìœ¼ë©´ ê°ì 

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
[
    {{"content_index": 1, "relevance_score": 8.5, "reason": "êµ¬ì²´ì ì¸ ì‚¬ë¡€ì™€ ë°ì´í„° í¬í•¨"}},
    {{"content_index": 2, "relevance_score": 6.0, "reason": "í‚¤ì›Œë“œì™€ ê´€ë ¨ìˆìœ¼ë‚˜ ì¼ë°˜ì ì¸ ë‚´ìš©"}},
    ...
]"""

        try:
            response = await self.llm_service._call_llm(prompt, temperature=0.3)
            
            # JSON ì‘ë‹µ íŒŒì‹±
            scores_data = self._parse_relevance_scores(response)
            
            # ì ìˆ˜ë¥¼ ì›ë³¸ ì½˜í…ì¸ ì— ì ìš©
            scored_content = []
            for item in content_batch:
                # ê¸°ë³¸ê°’: ì¤‘ê°„ ì ìˆ˜ (í•„í„°ë§ ì‹¤íŒ¨ ì‹œ ì•ˆì „ì¥ì¹˜)
                relevance_score = 5.0
                reason = "ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨"
                
                # í•´ë‹¹ ì½˜í…ì¸ ì˜ ì ìˆ˜ ì°¾ê¸°
                content_idx = content_batch.index(item) + 1
                for score_item in scores_data:
                    if score_item.get('content_index') == content_idx:
                        relevance_score = float(score_item.get('relevance_score', 5.0))
                        reason = score_item.get('reason', 'ì´ìœ  ì—†ìŒ')
                        break
                
                # ì ìˆ˜ ì •ë³´ ì¶”ê°€
                enhanced_item = item.copy()
                enhanced_item['relevance_score'] = relevance_score
                enhanced_item['relevance_reason'] = reason
                
                scored_content.append(enhanced_item)
            
            return scored_content
            
        except Exception as e:
            logger.error(f"âŒ ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨: {str(e)}")
            # ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ ì ìˆ˜ë¡œ ë°˜í™˜
            return [
                {**item, 'relevance_score': 5.0, 'relevance_reason': 'LLM í‰ê°€ ì‹¤íŒ¨'}
                for item in content_batch
            ]
    
    def _parse_relevance_scores(self, llm_response: str) -> List[Dict[str, Any]]:
        """LLM ì‘ë‹µì—ì„œ ê´€ë ¨ì„± ì ìˆ˜ íŒŒì‹±"""
        try:
            # JSON ë¸”ë¡ ì¶”ì¶œ
            response_clean = llm_response.strip()
            if '```json' in response_clean:
                response_clean = response_clean.split('```json')[1].split('```')[0].strip()
            elif '```' in response_clean:
                response_clean = response_clean.split('```')[1].strip()
            
            scores_data = json.loads(response_clean)
            
            # ë°ì´í„° ìœ íš¨ì„± ê²€ì¦
            if not isinstance(scores_data, list):
                raise ValueError("ì‘ë‹µì´ ë¦¬ìŠ¤íŠ¸ í˜•íƒœê°€ ì•„ë‹˜")
            
            # ê° í•­ëª© ê²€ì¦ ë° ì •ë¦¬
            validated_scores = []
            for item in scores_data:
                if isinstance(item, dict) and 'content_index' in item and 'relevance_score' in item:
                    # ì ìˆ˜ ë²”ìœ„ ì œí•œ (0-10)
                    score = max(0.0, min(10.0, float(item['relevance_score'])))
                    validated_scores.append({
                        'content_index': int(item['content_index']),
                        'relevance_score': score,
                        'reason': item.get('reason', 'ì´ìœ  ì—†ìŒ')
                    })
            
            return validated_scores
            
        except Exception as e:
            logger.warning(f"âš ï¸ LLM ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {str(e)}")
            logger.warning(f"   ì‘ë‹µ ë‚´ìš©: {llm_response[:200]}...")
            return []
    
    def _ensure_minimum_quality_content(
        self, 
        filtered_content: List[Dict[str, Any]], 
        original_content: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """ìµœì†Œ ê³ í’ˆì§ˆ ì½˜í…ì¸  ìˆ˜ ë³´ì¥"""
        
        if len(filtered_content) >= self.MIN_HIGH_QUALITY_POSTS:
            return filtered_content
        
        logger.info(f"ğŸ“ˆ ìµœì†Œ í’ˆì§ˆ ì½˜í…ì¸  ìˆ˜ ë¯¸ë‹¬ ({len(filtered_content)}/{self.MIN_HIGH_QUALITY_POSTS})")
        logger.info("   ì¶”ê°€ ì½˜í…ì¸ ë¥¼ í¬í•¨í•©ë‹ˆë‹¤")
        
        # ì´ë¯¸ í¬í•¨ëœ ì½˜í…ì¸  ID ëª©ë¡
        included_ids = {item.get('id') for item in filtered_content}
        
        # ì›ë³¸ì—ì„œ ì•„ì§ í¬í•¨ë˜ì§€ ì•Šì€ ì½˜í…ì¸  ì¤‘ ì ìˆ˜ê°€ ë†’ì€ ê²ƒë“¤ ì¶”ê°€
        additional_content = [
            item for item in original_content 
            if item.get('id') not in included_ids
        ]
        
        # ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ì¶”ê°€
        additional_content.sort(key=lambda x: x.get('score', 0), reverse=True)
        
        # í•„ìš”í•œ ë§Œí¼ ì¶”ê°€
        needed_count = self.MIN_HIGH_QUALITY_POSTS - len(filtered_content)
        selected_additional = additional_content[:needed_count]
        
        # ì¶”ê°€ëœ ì½˜í…ì¸ ì— ê¸°ë³¸ ê´€ë ¨ì„± ì ìˆ˜ ë¶€ì—¬
        for item in selected_additional:
            if 'relevance_score' not in item:
                item['relevance_score'] = 5.5  # ì„ê³„ê°’ë³´ë‹¤ ì•½ê°„ ë†’ì€ ê¸°ë³¸ ì ìˆ˜
                item['relevance_reason'] = 'ìµœì†Œ ì½˜í…ì¸  ìˆ˜ ë³´ì¥ì„ ìœ„í•´ ì¶”ê°€'
        
        final_content = filtered_content + selected_additional
        logger.info(f"âœ… ì´ {len(final_content)}ê°œ ì½˜í…ì¸ ë¡œ ì¡°ì • ì™„ë£Œ")
        
        return final_content
    
    def _calculate_average_score(self, content_list: List[Dict[str, Any]]) -> float:
        """í‰ê·  ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚°"""
        if not content_list:
            return 0.0
        
        scores = [item.get('relevance_score', 0) for item in content_list]
        return sum(scores) / len(scores)
    
    async def get_filtering_summary(self, filtered_content: List[Dict[str, Any]]) -> Dict[str, Any]:
        """í•„í„°ë§ ê²°ê³¼ ìš”ì•½ ì •ë³´ ìƒì„±"""
        
        if not filtered_content:
            return {
                'total_count': 0,
                'high_quality_count': 0,
                'average_score': 0.0,
                'score_distribution': {}
            }
        
        total_count = len(filtered_content)
        high_quality_count = len([item for item in filtered_content if item.get('relevance_score', 0) >= 8.0])
        average_score = self._calculate_average_score(filtered_content)
        
        # ì ìˆ˜ ë¶„í¬ ê³„ì‚°
        score_ranges = {
            '9-10ì  (ìµœê³ í’ˆì§ˆ)': 0,
            '7-8ì  (ê³ í’ˆì§ˆ)': 0,
            '5-6ì  (ë³´í†µí’ˆì§ˆ)': 0,
            '3-4ì  (ë‚®ì€í’ˆì§ˆ)': 0,
            '0-2ì  (ë§¤ìš°ë‚®ìŒ)': 0
        }
        
        for item in filtered_content:
            score = item.get('relevance_score', 0)
            if score >= 9:
                score_ranges['9-10ì  (ìµœê³ í’ˆì§ˆ)'] += 1
            elif score >= 7:
                score_ranges['7-8ì  (ê³ í’ˆì§ˆ)'] += 1
            elif score >= 5:
                score_ranges['5-6ì  (ë³´í†µí’ˆì§ˆ)'] += 1
            elif score >= 3:
                score_ranges['3-4ì  (ë‚®ì€í’ˆì§ˆ)'] += 1
            else:
                score_ranges['0-2ì  (ë§¤ìš°ë‚®ìŒ)'] += 1
        
        return {
            'total_count': total_count,
            'high_quality_count': high_quality_count,
            'average_score': average_score,
            'score_distribution': score_ranges
        }